{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8b9c5f76",
   "metadata": {},
   "source": [
    "# NLP Poem Classifier: Edgar Allan Poe & Robert Frost #"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9e601e0",
   "metadata": {},
   "source": [
    "## Import Files & APIs ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cd9de970",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File 'edgar_allan_poe.txt' already there; not retrieving.\n",
      "\n",
      "File 'robert_frost.txt' already there; not retrieving.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget -nc https://raw.githubusercontent.com/lazyprogrammer/machine_learning_examples/master/hmm_class/edgar_allan_poe.txt\n",
    "!wget -nc https://raw.githubusercontent.com/lazyprogrammer/machine_learning_examples/master/hmm_class/robert_frost.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "17fe4ee8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/james/opt/anaconda3/lib/python3.8/site-packages/scipy/__init__.py:138: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5)\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion} is required for this version of \"\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import string\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2be81ef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_files = [\n",
    "  'edgar_allan_poe.txt',\n",
    "  'robert_frost.txt',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1300360c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LO! Death hath rear'd himself a throne\r\n",
      "In a strange city, all alone,\r\n",
      "Far down within the dim west\r\n",
      "Where the good, and the bad, and the worst, and the best,\r\n",
      "Have gone to their eternal rest.\r\n",
      "â€‰\r\n",
      "There shrines, and palaces, and towers\r\n",
      "Are not like any thing of ours\r\n",
      "Oh no! O no! ours never loom\r\n",
      "To heaven with that ungodly gloom!\r\n"
     ]
    }
   ],
   "source": [
    "!head edgar_allan_poe.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6c713b48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Two roads diverged in a yellow wood,\r\n",
      "And sorry I could not travel both\r\n",
      "And be one traveler, long I stood\r\n",
      "And looked down one as far as I could\r\n",
      "To where it bent in the undergrowth; \r\n",
      "\r\n",
      "Then took the other, as just as fair,\r\n",
      "And having perhaps the better claim\r\n",
      "Because it was grassy and wanted wear,\r\n",
      "Though as for that the passing there\r\n"
     ]
    }
   ],
   "source": [
    "!head robert_frost.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "140fa622",
   "metadata": {},
   "source": [
    "## Data Cleaning and Preparation ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "79caf678",
   "metadata": {},
   "outputs": [],
   "source": [
    "samples_list = []\n",
    "labels = []\n",
    "for idx, file in enumerate(input_files):\n",
    "    for line in open(file, \"r\"):\n",
    "        line = line.rstrip().lower()\n",
    "        if line:\n",
    "            line = line.translate(str.maketrans('', '', string.punctuation))\n",
    "            samples_list.append(line)\n",
    "            labels.append(idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c972fc44",
   "metadata": {},
   "source": [
    "## Convert Data to Integers ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bd4a73b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into training and testing sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(samples_list, labels, test_size=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "495ea17b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create word to integer dictionary\n",
    "word_idx_dict = {\"UNKNOWN\": 0}\n",
    "idx = 1\n",
    "for line in samples_list:\n",
    "    for word in line.split():\n",
    "        if word not in word_idx_dict:\n",
    "            word_idx_dict[word] = idx\n",
    "            idx += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "08326afc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert each line to integer list\n",
    "x_train_int = []\n",
    "x_test_int = []\n",
    "\n",
    "for line in x_train:\n",
    "    line_as_int = [word_idx_dict[word] for word in line.split()]\n",
    "    x_train_int.append(line_as_int)\n",
    "    \n",
    "for line in x_test:\n",
    "    line_as_int = [word_idx_dict.get(word, 0) for word in line.split()]\n",
    "    x_test_int.append(line_as_int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6c64371",
   "metadata": {},
   "source": [
    "## Train Data Using Markov Models ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "12a4db01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create initial state distributions and state transition matrices for each label\n",
    "V = len(word_idx_dict)\n",
    "\n",
    "pi0 = np.ones(V)\n",
    "A0 = np.ones((V, V))\n",
    "\n",
    "pi1 = np.ones(V)\n",
    "A1 = np.ones((V, V))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e8d91fc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update pi's and A's to contain counts of each initial state/transition\n",
    "for i, line in enumerate(x_train_int):\n",
    "    update_pi = pi0 if y_train[i] == 0 else pi1\n",
    "    update_A = A0 if y_train[i] == 0 else A1\n",
    "    prev_idx = None\n",
    "    for idx in line:\n",
    "        if prev_idx == None:\n",
    "            update_pi[idx] += 1\n",
    "        else:\n",
    "            update_A[prev_idx, idx] += 1\n",
    "        prev_idx = idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f1146960",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize pi's and A's\n",
    "pi0 /= pi0.sum()\n",
    "A0 /= A0.sum(axis=1, keepdims=True)\n",
    "\n",
    "pi1 /= pi1.sum()\n",
    "A1 /= A1.sum(axis=1, keepdims=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c38a88da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Log the values in pi's and A's\n",
    "log_pi0 = np.log(pi0)\n",
    "log_A0 = np.log(A0)\n",
    "\n",
    "log_pi1 = np.log(pi1)\n",
    "log_A1 = np.log(A1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5b7480a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute priors\n",
    "total_0 = sum(y == 0 for y in y_train)\n",
    "total_1 = sum(y == 1 for y in y_train)\n",
    "\n",
    "prior_0 = total_0 / len(y_train)\n",
    "prior_1 = total_1 / len(y_train)\n",
    "\n",
    "log_prior_0 = np.log(prior_0)\n",
    "log_prior_1 = np.log(prior_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88b70403",
   "metadata": {},
   "source": [
    "## Build Classifier for Poems ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "885d11cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PoemClassifier:\n",
    "    def __init__(self, log_As, log_pis, log_priors):\n",
    "        self.log_As = log_As\n",
    "        self.log_pis = log_pis\n",
    "        self.log_priors = log_priors\n",
    "        self.K = len(log_priors) # Number of classes\n",
    "    \n",
    "    def _compute_log_likelihood(self, input_, class_):\n",
    "        log_A = self.log_As[class_]\n",
    "        log_pi = self.log_pis[class_]\n",
    "        \n",
    "        log_prob = 0\n",
    "        prev_idx = None\n",
    "        for idx in input_:\n",
    "            if prev_idx == None:\n",
    "                log_prob = log_pi[idx]\n",
    "            else:\n",
    "                log_prob += log_A[prev_idx, idx]\n",
    "            \n",
    "            prev_idx = idx\n",
    "\n",
    "        return log_prob\n",
    "    \n",
    "    def predict(self, inputs):\n",
    "        predictions = np.zeros(len(inputs))\n",
    "        for i, input_ in enumerate(inputs):\n",
    "            posteriors = [self._compute_log_likelihood(input_, c) + self.log_priors[c] \\\n",
    "                          for c in range(self.K)]\n",
    "            pred = np.argmax(posteriors)\n",
    "            predictions[i] = pred\n",
    "        return predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a347f2c",
   "metadata": {},
   "source": [
    "## Test Poem Classifier ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9a61320a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create PoemClassifier object\n",
    "clf = PoemClassifier([log_A0, log_A1], [log_pi0, log_pi1], [log_prior_0, log_prior_1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "98d0373a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 0.9969040247678018\n"
     ]
    }
   ],
   "source": [
    "# Test over training set\n",
    "p_train = clf.predict(x_train_int)\n",
    "print(f\"Train accuracy: {np.mean(p_train == y_train)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ea045b17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.8293135435992579\n"
     ]
    }
   ],
   "source": [
    "# Test over testing set\n",
    "p_test = clf.predict(x_test_int)\n",
    "print(f\"Test accuracy: {np.mean(p_test == y_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "474fb74b",
   "metadata": {},
   "source": [
    "## Confusion Matrix & F-score ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a6448479",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set confusion matrix:\n",
      "[[ 542    5]\n",
      " [   0 1068]]\n",
      "\n",
      "Testing set confusion matrix:\n",
      "[[ 97  74]\n",
      " [ 18 350]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, f1_score\n",
    "\n",
    "cm = confusion_matrix(y_train, p_train)\n",
    "cm_test = confusion_matrix(y_test, p_test)\n",
    "\n",
    "print(f\"Training set confusion matrix:\\n{cm}\\n\")\n",
    "print(f\"Testing set confusion matrix:\\n{cm_test}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "df66e4ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set F-score: 0.9976646426903316\n",
      "\n",
      "Testing set F-score: 0.8838383838383838\n"
     ]
    }
   ],
   "source": [
    "print(f\"Training set F-score: {f1_score(y_train, p_train)}\\n\")\n",
    "print(f\"Testing set F-score: {f1_score(y_test, p_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6036fde1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
